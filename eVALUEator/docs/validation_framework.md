# Validation Framework Documentation

This document explains the systematic approach to validating business opportunities before investing significant time and resources.

## The Problem

Many founders (myself included) spend months building products that fail because they skip proper validation. Common mistakes:

- Building based on assumptions, not evidence
- Confusing "cool idea" with "people will pay"
- Not understanding if the problem is painful enough
- Missing market size or competition issues

**This framework helps you validate in days, not months.**

## The Four-Step Process

### Step 0: Discovery & Prioritization (This Tool)
**Goal**: Gather evidence and score opportunities
**Time**: 1-3 days
**Output**: Ranked list with confidence scores

### Step 1: Problem Validation
**Goal**: Confirm problem exists and is painful
**Method**: Deep dive into community discussions
**Time**: 3-5 days
**Output**: Pass/fail gate

### Step 2: Solution Validation
**Goal**: Confirm people want YOUR solution
**Method**: Landing page or prototype testing
**Time**: 1-2 weeks
**Output**: Signup rate, engagement metrics

### Step 3: Willingness to Pay
**Goal**: Confirm people will actually pay
**Method**: Conversations, pre-orders, MVPs
**Time**: 2-4 weeks
**Output**: Revenue or strong commitments

---

## Step 0: Scoring Framework

This tool automates Step 0 by scoring opportunities on 12 dimensions.

### 1. Problem-Solution Fit (30 points)

#### Aspiration Clarity (0-10)
*Can the ICP articulate what they want to achieve?*

**What to look for:**
- Specific outcomes they desire
- Clear transformation they want
- Measurable goals they mention

**Red flags:**
- Vague wishes like "be happier"
- No clear end state
- Different people want different things

**Examples:**
- ✅ 9/10: "I want to reduce feedback time from 3 hours to 30 minutes per week"
- ⚠️ 5/10: "I want teaching to be easier"
- ❌ 2/10: "I want to feel less stressed"

#### Workaround Pain (0-10)
*How painful is their current solution?*

**What to look for:**
- Active complaints in communities
- Time spent on workarounds
- Money spent on inadequate solutions
- Emotional language (frustrated, exhausted)

**Red flags:**
- "It's fine" or "not that bad"
- No current solution (might not be important)
- Free alternatives work well enough

**Examples:**
- ✅ 9/10: "Spending 10 hours/week on this, considering quitting"
- ⚠️ 5/10: "Would be nice if this was better"
- ❌ 2/10: "Works okay, just a minor annoyance"

#### Stuck Pattern (0-10)
*Are they repeatedly trying and failing?*

**What to look for:**
- "I've tried X, Y, Z and nothing works"
- Questions like "What should I do?"
- Multiple threads about same problem
- Expressions of confusion or uncertainty

**Red flags:**
- Haven't tried solving it yet
- Found a working solution
- Only complaining, not seeking help

**Examples:**
- ✅ 9/10: "Tried 3 different apps, none handle my situation"
- ⚠️ 5/10: "Looking for suggestions"
- ❌ 2/10: "Never really thought about fixing this"

### 2. Market Signals (30 points)

#### Market Size (0-10)
*How many people have this problem?*

**Estimation methods:**
- Community member counts
- Industry reports
- Similar product user bases
- Search volume

**Scoring:**
- 10: 1M+ potential users
- 8: 100K-1M
- 6: 10K-100K
- 4: 1K-10K
- 2: <1K

**Note:** Smaller can be better if budget is high (efficiency score)

#### Budget Confirmed (0-10)
*Evidence they pay for similar tools?*

**What to look for:**
- Mentions of paid tools/services
- Price points being discussed
- "Worth the subscription" comments
- Complaints about pricing (proves willingness to pay)

**Red flags:**
- Only free tools mentioned
- "Would never pay for this"
- Active piracy discussions

**Examples:**
- ✅ 10/10: "I pay $50/mo for X and still struggling"
- ⚠️ 5/10: "Might consider paying if it was really good"
- ❌ 2/10: "Everything should be free"

#### Competition Gap (0-10)
*Are existing solutions leaving them underserved?*

**What to look for:**
- Complaints about existing tools
- "X is good but doesn't handle Y"
- Feature requests ignored by competitors
- Niche segments being overlooked

**Red flags:**
- "X tool is perfect"
- Dominant player serving everyone well
- Recent, well-funded competitors launched

**Examples:**
- ✅ 9/10: "All tools assume monogamy, useless for poly relationships"
- ⚠️ 5/10: "Current tools are okay, could be better"
- ❌ 2/10: "Notion solves this perfectly"

### 3. Founder-Market Fit (30 points)

#### Domain Expertise (0-10)
*Does founder understand this space?*

**What counts:**
- Years of experience in domain
- Direct exposure to problem
- Understanding of nuances/terminology
- Network in the space

**Scoring:**
- 10: Domain expert (5+ years)
- 8: Experienced (2-5 years)
- 6: Familiar (1 year, learning)
- 4: Studied it extensively
- 2: Complete outsider

#### Audience Access (0-10)
*Can founder reach these people?*

**What counts:**
- Part of the community
- Existing audience/followers
- Relationships with influencers
- Platform to share from

**Red flags:**
- No presence in space
- Community requires invitation
- Gatekeepers blocking access

#### Passion Level (0-10)
*Will founder stay committed?*

**What to assess:**
- Personal connection to problem
- Emotional investment
- History of persistence
- Why THIS problem

**Red flags:**
- "Seems like an opportunity"
- Just following trends
- Easily distracted by new ideas

### 4. Execution Feasibility (30 points)

#### Technical Capability (0-10)
*Can founder build this?*

**Assessment:**
- 10: Has exact skills needed
- 8: Can build with some learning
- 6: Needs upskilling but possible
- 4: Needs contractors/co-founder
- 2: Way beyond capabilities

#### Reachability (0-10)
*Are target users findable online?*

**What to look for:**
- Active communities (Reddit, Discord, forums)
- High engagement rates
- Searchable, accessible
- Willing to engage with new people/products

#### Virality Potential (0-10)
*Will users naturally share?*

**Strong signals:**
- Inherent network effects
- Social/collaborative features
- Status-driven sharing
- "Show off" factor

**Examples:**
- ✅ 9/10: Dating app (needs others)
- ⚠️ 5/10: Productivity tool (might share)
- ❌ 2/10: Tax software (private, no sharing)

---

## Interpreting Scores

### Total Score (0-120)

- **90-120**: Strong opportunity, proceed with confidence
- **70-89**: Promising, validate Step 1 carefully
- **50-69**: Risky, needs more evidence
- **Below 50**: High risk of failure, reconsider

### Efficiency Score

Formula: `Total Score / (Market Size + 1)`

**Why it matters:**
- Smaller markets with strong signals often beat large markets
- Easier to dominate niche than compete in crowded space
- High efficiency = underserved, high-value segment

**Examples:**
- ENM Calendar: Score 85, Market 5 → Efficiency 14.2 (excellent)
- Generic Todo App: Score 75, Market 10 → Efficiency 6.8 (meh)

### Recommendation Thresholds

**Proceed**: Total ≥ 70 AND (Budget ≥ 7 OR Efficiency ≥ 10)
**Monitor**: Total 50-70, gather more evidence
**Reject**: Total < 50 OR Budget < 5

---

## Using This Tool

### Workflow

1. **Define opportunities** - Create list of ideas to validate
2. **Run validator** - System researches all in parallel
3. **Review findings** - Check evidence quality
4. **Compare scores** - Rank by total and efficiency
5. **Pick one** - Proceed to Step 1 with top choice

### Time Investment

- **Manual research**: 3-5 hours per opportunity
- **With this tool**: 30 minutes active + 2 hours passive
- **Savings**: Validate 5 opportunities in time it takes to do 1 manually

### Cost

- Per opportunity: ~$0.50 in API costs
- Validating 5 opportunities: ~$2.50
- Compare to: Months of wasted effort on wrong idea

---

## What This Doesn't Replace

This tool handles Step 0 (discovery). You still need:

- **Step 1**: Deep community engagement
- **Step 2**: Landing page or prototype testing
- **Step 3**: Actual conversations and sales

But it dramatically reduces wasted effort by filtering out bad ideas early.

---

## Case Study: My 7-Month Mistake

**What I did:**
- Had an idea, built for 7 months
- Minimal validation, mostly assumptions
- Launched to crickets

**What I should have done:**
- Run this validator first (would have shown red flags)
- Budget score would have been 3/10
- Market size was 8 but competition gap was 2/10
- Total score: ~55 (borderline reject)

**Result:** Would have saved 7 months

That's why this exists. Don't be me.

---

## Further Reading

- "The Mom Test" by Rob Fitzpatrick
- "Running Lean" by Ash Maurya
- "Traction" by Gabriel Weinberg
- "Obviously Awesome" by April Dunford
